{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EKoN6BQab1i5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from matplotlib import rcParams\n",
    "#import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING USER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9_zrOY_0chnK"
   },
   "outputs": [],
   "source": [
    "# Loading in data\n",
    "dataframe = pd.read_csv('steam-200k.csv')\n",
    "dataframe = dataframe.set_axis(['UserID' , 'Game', 'Purchase/Play','Hrs played', '0/1'], axis = 1)\n",
    "\n",
    "# Cleaning data\n",
    "\n",
    "# Removing weird symbols that appear often in game titles\n",
    "names2 = []\n",
    "for i in dataframe[\"Game\"]:\n",
    "  names2.append(i.replace('®' , '').replace('™' , '').lower())\n",
    "dataframe['p_names'] = names2  \n",
    "\n",
    "# Removing games with 'DLC' in their title, as they are not useful\n",
    "dlcs = []\n",
    "for i in dataframe['p_names']:\n",
    "  if 'dlc' in i:\n",
    "    dlcs.append(i)\n",
    "dlcs = np.unique(dlcs)  \n",
    "\n",
    "# Removing special editions/versions of games \n",
    "editions = []\n",
    "for i in dataframe['p_names']:\n",
    "  if 'edition' in i:\n",
    "    editions.append(i)\n",
    "editions = np.unique(editions) \n",
    "\n",
    "# Removing season passes\n",
    "seasonpass = []\n",
    "for i in dataframe['p_names']:\n",
    "  if 'season' in i:\n",
    "    seasonpass.append(i)\n",
    "seasonpass = np.unique(seasonpass) \n",
    "\n",
    "# Dropping both DLCs and special editions\n",
    "for i in dlcs:\n",
    "  dataframe.drop(dataframe[dataframe['p_names']==i].index, inplace=True)\n",
    "for i in editions:\n",
    "  dataframe.drop(dataframe[dataframe['p_names']==i].index, inplace=True)\n",
    "for i in seasonpass:\n",
    "  dataframe.drop(dataframe[dataframe['p_names']==i].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gTiVE6KbclAx"
   },
   "outputs": [],
   "source": [
    "# Creating a collumn Hours_played where we only include the playtime, so that the 'purchase' rows can be dropped later on\n",
    "\n",
    "dataframe['Hours_Played'] = dataframe['Hrs played'].astype('float32')\n",
    "\n",
    "dataframe.loc[(dataframe['Purchase/Play'] == 'purchase') & (dataframe['Hrs played'] == 1.0), 'Hours_Played'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kfIxmunkcoRq"
   },
   "outputs": [],
   "source": [
    "# Drop the 'purchase' rows\n",
    "clean_df = dataframe.drop_duplicates(['UserID', 'Game'], keep = 'last').drop(['Purchase/Play', 'Hrs played','0/1', 'Game'], axis = 1)\n",
    "top_10_games = clean_df['p_names'].value_counts()[0:10]\n",
    "\n",
    "# Drop all game titles that are played less than 25 hours as they are useless for generating recommendations\n",
    "tot_hrs_p_game = clean_df.groupby('p_names').sum()\n",
    "tot_hrs_p_game.drop(tot_hrs_p_game[tot_hrs_p_game['Hours_Played']>25].index, inplace=True)\n",
    "all_useless_games = np.unique(tot_hrs_p_game.index.get_level_values(0))\n",
    "for i in all_useless_games:\n",
    "  clean_df.drop(clean_df[clean_df['p_names']==i].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALCULATING RATINGS BASED ON PLAYTIME PER PERSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a collumn with all mean gametimes per game\n",
    "mean_gametime = clean_df.groupby('p_names').mean()\n",
    "mean_gametime = dict(mean_gametime[ 'Hours_Played'])\n",
    "avg_playtimes = []\n",
    "for i in clean_df['p_names']:\n",
    "  avg_playtimes.append(mean_gametime[i])\n",
    "clean_df['avg_playtime'] = avg_playtimes\n",
    "\n",
    "# Creating a list of the hours per player to calculate ratings\n",
    "hours_p_player = list(clean_df['Hours_Played'])\n",
    "avg_hours = list(clean_df['avg_playtime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating ratings based on the game time per player compared to the mean game time of that game\n",
    "ratings = []\n",
    "for i in range(0,len(hours_p_player)):\n",
    "  if hours_p_player[i]/avg_hours[i] > 1:\n",
    "    ratings.append(5)\n",
    "  elif hours_p_player[i]/avg_hours[i] > 0.8:\n",
    "    ratings.append(4)\n",
    "  elif hours_p_player[i]/avg_hours[i] > 0.5:\n",
    "    ratings.append(3)\n",
    "  elif hours_p_player[i]/avg_hours[i] > 0.1:\n",
    "    ratings.append(2)\n",
    "  else:\n",
    "    ratings.append(1)  \n",
    "\n",
    "clean_df['rating'] = ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0wYMupfRcrBK"
   },
   "outputs": [],
   "source": [
    "# Creating usefull variables for later on\n",
    "n_users = len(np.unique(clean_df['UserID']))\n",
    "n_games = len(np.unique(clean_df['p_names']))\n",
    "user_list = np.unique(clean_df['UserID'])\n",
    "item_list = np.unique(clean_df['p_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING STEAM GAMES DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the steam games dataset\n",
    "dataframe1 = pd.read_csv('steam.csv')\n",
    "dataframe2 = pd.read_csv('steam_requirements_data.csv')\n",
    "dataframe3 = pd.read_csv('steam_description_data.csv')\n",
    "dataframe1 = dataframe1.rename(columns={'appid': 'steam_appid'})\n",
    "dataframe1 = pd.merge(dataframe1,dataframe2, on='steam_appid')\n",
    "dataframe1 = pd.merge(dataframe1,dataframe3, on='steam_appid')\n",
    "\n",
    "# Stripping the game names of weird symbols\n",
    "names = []\n",
    "for i in dataframe1['name']:\n",
    "  names.append(i.replace('®' , '').replace('™' , '').replace(':', '').replace('’' , \"'\").lower())\n",
    "dataframe1['p_names'] = names\n",
    "\n",
    "names2 = []\n",
    "for i in dataframe[\"Game\"]:\n",
    "  names2.append(i.replace('®' , '').replace('™' , '').lower())\n",
    "dataframe['p_names'] = names2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jCsMOm-8ctRK"
   },
   "outputs": [],
   "source": [
    "# Dropping features I wont be using\n",
    "dataframe1 = dataframe1.drop(['english', 'publisher','achievements', 'positive_ratings','required_age', 'price', 'negative_ratings', 'average_playtime', 'median_playtime', 'owners', 'pc_requirements', 'mac_requirements', 'linux_requirements', 'minimum', 'recommended', 'about_the_game', 'short_description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'return to the black mesa research facility as one of the military specialists assigned to eliminate gordon freeman  experience an entirely new episode of single player action  meet fierce alien opponents  and experiment with new weaponry  named  game of the year  by the academy of interactive arts and sciences '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the metadata feature where all usefull features are merged into one feature\n",
    "dataframe1['metadata'] = dataframe1['detailed_description'].str.replace(';',' ').str.replace('.',' ').str.replace(\"'\",' ')\n",
    "dataframe1['metadata'] = dataframe1['metadata'].str.replace(',', ' ').replace(';',' ')\n",
    "\n",
    "dataframe1['metadata'][4].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATCHING DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching the player dataset with the steam dataset\n",
    "all_found_games = []\n",
    "for i in dataframe1['p_names']:\n",
    "    if i not in item_list:\n",
    "        dataframe1 = dataframe1.drop(dataframe1[dataframe1['p_names'] == i].index)\n",
    "    else:\n",
    "        all_found_games.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all games that are not in the games dataset\n",
    "for i in clean_df['p_names']:\n",
    "    if i not in all_found_games:\n",
    "        clean_df = clean_df.drop(clean_df[clean_df['p_names']==i].index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the steam ID's of the games to the Userdataset which makes it easier to work with\n",
    "steam_appid = []\n",
    "for item in clean_df['p_names']:\n",
    "    steam_appid.append(dataframe1.loc[dataframe1['p_names'] == item].index)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = []\n",
    "for i in steam_appid:\n",
    "    for j in dataframe1['steam_appid'].loc[i].values:\n",
    "        list2.append(j)\n",
    "clean_df['steam_appid'] = list2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARATION FOR THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns for easier use of the model\n",
    "clean_df = clean_df.rename(columns={'steam_appid':'contentId', 'UserID':'personId', 'rating':'eventStrength'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1 = dataframe1.rename(columns={'steam_appid':'contentId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the dataset for easier use of the model\n",
    "interactions_df = clean_df\n",
    "articles_df = dataframe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 11239\n",
      "# users with at least 5 interactions: 2814\n"
     ]
    }
   ],
   "source": [
    "# Only use users that have more than 5 games in their library\n",
    "\n",
    "users_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size().groupby('personId').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions: 70621\n",
      "# of interactions from users with at least 5 interactions: 57579\n"
     ]
    }
   ],
   "source": [
    "print('# of interactions: %d' % len(interactions_df))\n",
    "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df, \n",
    "               how = 'right',\n",
    "               left_on = 'personId',\n",
    "               right_on = 'personId')\n",
    "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique user/item interactions: 57579\n"
     ]
    }
   ],
   "source": [
    "# Optional function to smooth the ratings of the users with a log function.\n",
    "\n",
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "interactions_full_df = interactions_from_selected_users_df \\\n",
    "                    .groupby(['personId', 'contentId'])['eventStrength'].sum() \\\n",
    "                    .apply(smooth_user_preference).reset_index()\n",
    "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# interactions on Train set: 46063\n",
      "# interactions on Test set: 11516\n"
     ]
    }
   ],
   "source": [
    "# Splitting data in train/test set\n",
    "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
    "                                   stratify=interactions_full_df['personId'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing by personId to speed up the searches during evaluation\n",
    "\n",
    "interactions_full_indexed_df = interactions_full_df.set_index('personId')\n",
    "interactions_train_indexed_df = interactions_train_df.set_index('personId')\n",
    "interactions_test_indexed_df = interactions_test_df.set_index('personId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL EVALUATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function that checks all games in a users library\n",
    "\n",
    "def get_items_interacted(person_id, interactions_df):\n",
    "    interacted_items = interactions_df.loc[person_id]['contentId']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL EVALUATOR ###\n",
    "\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 50\n",
    "class ModelEvaluator:\n",
    "\n",
    "\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(articles_df['contentId'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset['contentId']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(person_id, \n",
    "                                               items_to_ignore=get_items_interacted(person_id, \n",
    "                                                                                    interactions_train_indexed_df), \n",
    "                                               topn=10000000000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=item_id%(2**32))\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['contentId'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['_person_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTUAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<958x2500 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 102527 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "                     ngram_range=(1, 2),\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=2500,\n",
    "                     stop_words='english')\n",
    "\n",
    "item_ids = articles_df['contentId'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform( articles_df['metadata'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names()\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for building userprofiles ###\n",
    "\n",
    "def get_item_profile(item_id):\n",
    "    idx = item_ids.index(item_id)\n",
    "    item_profile = tfidf_matrix[idx:idx+1]\n",
    "    return item_profile\n",
    "\n",
    "def get_item_profiles(ids):\n",
    "    item_profiles_list = [get_item_profile(x) for x in ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_users_profile(person_id, interactions_indexed_df):\n",
    "    interactions_person_df = interactions_indexed_df.loc[person_id]\n",
    "    user_item_profiles = get_item_profiles(interactions_person_df['contentId'])\n",
    "    \n",
    "    user_item_strengths = np.array(interactions_person_df['eventStrength']).reshape(-1,1)\n",
    "    #Weighted average of item profiles by the interactions strength\n",
    "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
    "    return user_profile_norm\n",
    "\n",
    "def build_users_profiles(): \n",
    "    interactions_indexed_df = interactions_train_df[interactions_train_df['contentId'] \\\n",
    "                                                   .isin(articles_df['contentId'])].set_index('personId')\n",
    "    user_profiles = {}\n",
    "    for person_id in interactions_indexed_df.index.unique():\n",
    "        user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df)\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2814"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profiles = build_users_profiles()\n",
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2500)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isaac</td>\n",
       "      <td>0.224737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strong br</td>\n",
       "      <td>0.169798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>support</td>\n",
       "      <td>0.152720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rogue</td>\n",
       "      <td>0.138788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>items</td>\n",
       "      <td>0.138418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>magic</td>\n",
       "      <td>0.129231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unique</td>\n",
       "      <td>0.125737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>secrets</td>\n",
       "      <td>0.124471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>different</td>\n",
       "      <td>0.119079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cards</td>\n",
       "      <td>0.113088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  relevance\n",
       "0      isaac   0.224737\n",
       "1  strong br   0.169798\n",
       "2    support   0.152720\n",
       "3      rogue   0.138788\n",
       "4      items   0.138418\n",
       "5      magic   0.129231\n",
       "6     unique   0.125737\n",
       "7    secrets   0.124471\n",
       "8  different   0.119079\n",
       "9      cards   0.113088"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how a profile looks like\n",
    "myprofile = user_profiles[128470551]\n",
    "print(myprofile.shape)\n",
    "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        user_profiles[128470551].flatten().tolist()), key=lambda x: -x[1])[:10],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECOMMENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, items_df=None):\n",
    "        self.item_ids = item_ids\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
    "        #Computes the cosine similarity between the user profile and all item profiles\n",
    "        cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\n",
    "        #Gets the top similar items\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        #Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_items = self._get_similar_items_to_user_profile(user_id)\n",
    "        #Ignores items the user has already interacted\n",
    "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['contentId', 'recStrength']) \\\n",
    "                                    .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'contentId', \n",
    "                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "content_based_recommender_model = ContentBasedRecommender(articles_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTS OF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "2813 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.24409517193469954, 'recall@10': 0.3785168461271275}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>62990992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>30246419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>53875128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>11403772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>22301321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>47457723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>20772968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>49893565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>24469287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>36546868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "45              5              8                61  0.081967   0.131148   \n",
       "206             5             11                50  0.100000   0.220000   \n",
       "266             3             12                49  0.061224   0.244898   \n",
       "388             5             11                48  0.104167   0.229167   \n",
       "225             4             11                48  0.083333   0.229167   \n",
       "233             3              8                46  0.065217   0.173913   \n",
       "93              6             12                45  0.133333   0.266667   \n",
       "734             9             14                42  0.214286   0.333333   \n",
       "200             2              5                42  0.047619   0.119048   \n",
       "153             7             12                41  0.170732   0.292683   \n",
       "\n",
       "     _person_id  \n",
       "45     62990992  \n",
       "206    30246419  \n",
       "266    53875128  \n",
       "388    11403772  \n",
       "225    22301321  \n",
       "233    47457723  \n",
       "93     20772968  \n",
       "734    49893565  \n",
       "200    24469287  \n",
       "153    36546868  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-70b7c282856d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcontent_based_recommender_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecommend_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "content_based_recommender_model.recommend_items(self ,user_id=5250, topn=20, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "content_based de nieuwe.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
